### stage 1: ASD_GDD 和 DLD
import pandas as pd
import numpy as np
from numpy import *
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.metrics import log_loss, roc_auc_score,f1_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
import keras
import math
from sklearn.model_selection import KFold
from keras.wrappers.scikit_learn import KerasClassifier
from xgboost.sklearn import XGBClassifier
import xgboost as xgb
from sklearn.utils.class_weight import compute_sample_weight
from keras.utils import to_categorical # one-hot编码
import os
import warnings
warnings.filterwarnings("ignore")

### load data
df = pd.read_csv('/home/kesci/input/data7617/dat.1944.csv')
tdf = pd.read_csv('/home/kesci/input/data7617/dat.60.csv')
df = df.replace('ASD', 0)
df = df.replace('DLD', 1)
df = df.replace('GDD', 0)
tdf = tdf.replace('ASD', 0)
tdf = tdf.replace('DLD', 1)
tdf = tdf.replace('GDD', 0)
col = ['diag','adaptation','social','fine','gross']
col1 = ['adaptation','social','fine','gross']
dat = df[col]
grp = dat['diag']
x_test = tdf[col1]
y_test = tdf['diag']

x_train = dat[col[1:]]
y_train = dat['diag']

xlf = XGBClassifier(
max_depth = 3,
learning_rate = 0.0001,
n_estimators = 1,
silent = True,
eval_metric = 'error',
 objective = 'binary:logistic',
gamma = 0.2,
subsample = 1,
colsample_bytree = 1)  

xgc = xlf

xgc.fit(x_train, y_train, sample_weight = compute_sample_weight("balanced", y_train))
pred_test = xgc.predict_proba(x_test)

### predict test
pred_res = np.argmax(pred_test, axis=1)
mat_test = confusion_matrix(y_test, pred_res)
acc_all_test = np.diag(mat_test)/mat_test.sum(axis=1)
acc_test = accuracy_score(y_test, pred_res)
acc1 = acc_all_test[0]
acc2 = acc_all_test[1]

print('acc:\n', acc_test)
print('r:\n', acc_all_test)
print('matrix:\n', mat_test)

xgb.to_graphviz(xgc, num_trees=0)

### stage2: ASD 和 GDD
df = pd.read_csv('/home/kesci/input/data7617/dat.1944.csv')
tdf = pd.read_csv('/home/kesci/input/data7617/dat.60.csv')
df = df.replace('ASD', 0)
df = df.replace('GDD', 1)
tdf = tdf.replace('ASD', 0)
tdf = tdf.replace('GDD', 1)
grp_train = df['diag']
grp_test = tdf['diag']
grp_train_ind1 = grp_train.index[grp_train == 0]
grp_train_ind2 = grp_train.index[grp_train == 1]
grp_train_ind = np.concatenate((grp_train_ind1, grp_train_ind2))
train = df.iloc[grp_train_ind]
col = ['diag','mchathigh']
x_train = train[col[1:]]
y_train = train['diag']

xlf = XGBClassifier(
max_depth = 1,
learning_rate = 0.0001,
n_estimators = 1,
silent = True,
eval_metric = 'error',
 objective = 'binary:logistic',
gamma = 0.2,
subsample = 1,
colsample_bytree = 1)  

xgc2 = xlf

xgc2.fit(x_train, y_train, sample_weight = compute_sample_weight("balanced", y_train))
# Select the samples whose prediction result is 0 in the first stage
a = np.where((pred_res==0) & ((grp_test==0)|((grp_test==1))))
x_test0 = tdf.iloc[a]
x_test = x_test0[['mchathigh']]
x_test.reset_index(drop=True, inplace=True)
y_test2 = grp_test.iloc[a]
y_test2.reset_index(drop=True, inplace=True)
pred_res2 = xgc2.predict(x_test)
print(pred_res2)
print(y_test2)
pred_res2 = pd.DataFrame(pred_res2)
y_test2 = pd.DataFrame(y_test2)
res = pd.concat([x_test, y_test2, pred_res2], axis=1)
res.to_csv('.../res.csv', index=False)
xgb.to_graphviz(xgc2, num_trees=0) 
 





  
 
 



